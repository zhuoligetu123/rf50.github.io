WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.919
You've done a great job thus far,

00:00:01.919 --> 00:00:05.125
implementing the Kalman filter in one dimension.

00:00:05.125 --> 00:00:08.714
Now it's time to consider systems with higher dimensions,

00:00:08.714 --> 00:00:14.294
after all most the real life processes that we'd like to model are multi-dimensional.

00:00:14.294 --> 00:00:15.539
For instance, the x,

00:00:15.539 --> 00:00:17.474
y location of a robot.

00:00:17.475 --> 00:00:19.545
Let's step through what a multi-dimensional

00:00:19.545 --> 00:00:22.800
otherwise known as a multivariate Gaussian looks like.

00:00:22.800 --> 00:00:27.405
And then move on to code a 2-D Kalman filter in C++.

00:00:27.405 --> 00:00:30.750
A 2-D Gaussian can also be represented as so,

00:00:30.750 --> 00:00:33.509
where the contour lines show variations in height.

00:00:33.509 --> 00:00:38.159
We will be using two-dimensional Gaussian as examples but the same concepts

00:00:38.159 --> 00:00:43.064
and processes that you learn here can be applied to higher dimensional Gaussian as well.

00:00:43.064 --> 00:00:45.071
For a one dimensional Gaussian,

00:00:45.072 --> 00:00:48.390
the mean was represented by a single value, Mieux,

00:00:48.390 --> 00:00:50.490
for two dimensional Gaussian,

00:00:50.490 --> 00:00:51.929
the mean is a vector,

00:00:51.929 --> 00:00:55.994
with two values one for each of the two dimensions.

00:00:55.994 --> 00:00:57.989
An N dimensional Gaussian,

00:00:57.990 --> 00:01:01.245
would have a mean vector that are sized N by 1.

00:01:01.244 --> 00:01:06.855
Similarly, while a one dimensional Gaussian has a single value for the variance,

00:01:06.855 --> 00:01:13.064
a two dimensional Gaussian has a covariance matrix represented by an uppercase Sigma.

00:01:13.064 --> 00:01:18.399
The covariance matrix represents the spread of the Gaussian into two dimensions,

00:01:18.400 --> 00:01:22.920
an N dimensional Gaussian would have a covariance matrix that is of size N

00:01:22.920 --> 00:01:28.915
by N. The diagonal values of the matrix represent the variance.

00:01:28.915 --> 00:01:32.925
While the off diagonal elements represent the correlation terms.

00:01:32.924 --> 00:01:38.659
An important fact to note is that the covariance matrix is always symmetrical.

00:01:38.659 --> 00:01:40.829
In the case of the 2-D Gaussian,

00:01:40.829 --> 00:01:44.010
the two off diagonal elements are equivalent.

00:01:44.010 --> 00:01:47.672
To make better sense of what a covariance matrix represents,

00:01:47.671 --> 00:01:51.599
Let's take a look at a few examples of two-dimensional Gaussians.

00:01:51.599 --> 00:01:53.894
Let's fix our mean into an arbitrary point,

00:01:53.894 --> 00:01:57.200
and manipulate the values and the covariance matrix.

00:01:57.200 --> 00:01:59.655
If the x and y variances are both small,

00:01:59.655 --> 00:02:01.034
and equal to one another,

00:02:01.034 --> 00:02:04.109
the 2-D Gaussian representation will be circular.

00:02:04.109 --> 00:02:06.750
In such a case, you are equally certain about

00:02:06.750 --> 00:02:09.990
the location of an object in each dimension.

00:02:09.990 --> 00:02:12.420
However, it's possible that you are quite certain

00:02:12.419 --> 00:02:15.359
about the location of an object in the x axis,

00:02:15.360 --> 00:02:17.880
but not so much on the y axis.

00:02:17.879 --> 00:02:23.335
In such a case, the contra lines of the Gaussian will start to take on an oval shape.

00:02:23.335 --> 00:02:26.025
Notice that the correlation terms are zero,

00:02:26.025 --> 00:02:28.545
if the correlation terms are non-zero,

00:02:28.544 --> 00:02:30.569
the two axis are correlated,

00:02:30.569 --> 00:02:33.479
and you'll have a skewed oval as you see here.

00:02:33.479 --> 00:02:37.019
Depending on whether the terms multiply out to a positive value,

00:02:37.020 --> 00:02:42.420
or a negative value your oval will skew to the right, or left respectively.

00:02:42.419 --> 00:02:45.344
Then once you get information about one axis,

00:02:45.344 --> 00:02:49.414
it will reveal information about the other due to the correlation.

00:02:49.414 --> 00:02:51.750
A multivariate Gaussian can be modeled with

00:02:51.750 --> 00:02:55.965
the following equation D represents the number of dimensions present,

00:02:55.965 --> 00:02:59.354
and you'll notice that if you plug in D equals 1 into the formula,

00:02:59.354 --> 00:03:02.310
it simplifies to the one-dimensional Gaussian formula

00:03:02.310 --> 00:03:04.000
that you were presented with earlier.

